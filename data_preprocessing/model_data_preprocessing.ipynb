{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data to fit model format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to preprocess the data to fit the model format. The data is preprocessed in the following steps:\n",
    "1. Load the scripts and clean them\n",
    "2. Load the severity ratings of for each imdb-id\n",
    "3. Load the the scripts as 2 dimension tensor lists, containing the embedded sentences of a scritp\n",
    "4. Merge all the data into a dataframe of the format fitting for the RNN mode (id | Aspect | None | Mild | Moderate | Severe | Total_votes | Aspect_rating | text)\n",
    "5. Group the dataframes by aspect ('nudity', 'violence', 'profanity', 'frightening', 'alcohol')\n",
    "6. Split the dataframes into train, validation and test sets\n",
    "7. Save the datafranes as pickle files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_from_id(id):\n",
    "    script = open('../data/script/' + id + '.script', 'r').read()\n",
    "    # print(script)\n",
    "    script = script.replace(\"'\", \" \").replace('\"', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\b', ' ').replace('\\\\', ' ')\n",
    "    return script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id       Aspect  None  Mild  Moderate  Severe  Total_votes  \\\n",
      "0    tt0032138       nudity    93     3         0       8          104   \n",
      "1    tt0032138     violence    23    61         8       8          100   \n",
      "2    tt0032138    profanity    86     4         0       5           95   \n",
      "3    tt0032138      alcohol    76    10         1       6           93   \n",
      "4    tt0032138  frightening    10    63        17      10          100   \n",
      "..         ...          ...   ...   ...       ...     ...          ...   \n",
      "250  tt0080761       nudity    19   113       145      60          337   \n",
      "251  tt0080761     violence     6     8        36     147          197   \n",
      "252  tt0080761    profanity     9   120        36       4          169   \n",
      "253  tt0080761      alcohol    10   129        18       4          161   \n",
      "254  tt0080761  frightening     6    16        45     111          178   \n",
      "\n",
      "     Aspect_rating                                               text  \n",
      "0                0  [[tensor(0.1276), tensor(-0.1368), tensor(0.79...  \n",
      "1                1  [[tensor(0.1276), tensor(-0.1368), tensor(0.79...  \n",
      "2                0  [[tensor(0.1276), tensor(-0.1368), tensor(0.79...  \n",
      "3                0  [[tensor(0.1276), tensor(-0.1368), tensor(0.79...  \n",
      "4                1  [[tensor(0.1276), tensor(-0.1368), tensor(0.79...  \n",
      "..             ...                                                ...  \n",
      "250              2  [[tensor(-0.1788), tensor(0.2544), tensor(0.93...  \n",
      "251              3  [[tensor(-0.1788), tensor(0.2544), tensor(0.93...  \n",
      "252              1  [[tensor(-0.1788), tensor(0.2544), tensor(0.93...  \n",
      "253              1  [[tensor(-0.1788), tensor(0.2544), tensor(0.93...  \n",
      "254              3  [[tensor(-0.1788), tensor(0.2544), tensor(0.93...  \n",
      "\n",
      "[255 rows x 9 columns]\n",
      "(255, 9)\n"
     ]
    }
   ],
   "source": [
    "inputFile = open('../data_gathering/baseline/output/imdb_id_with_age_rating_and_labels.txt')\n",
    "df_data = []\n",
    "\n",
    "with open(\"../data_gathering/baseline/output/imdb_id_with_embSentencesList50.pkl\", \"rb\") as f:\n",
    "    object = pkl.load(f)\n",
    "    df_embs = pd.DataFrame(object)\n",
    "    df_embs.rename(columns = {'imdb_id':'id'}, inplace=True)\n",
    "\n",
    "for line in inputFile:\n",
    "    line_data = line.strip().split(',')\n",
    "    # print(line_data)\n",
    "    line_data.append(int(line_data[3]) + int(line_data[4]) + int(line_data[5]) + int(line_data[6]))\n",
    "    \n",
    "    max_index = 0\n",
    "    max_value = 0\n",
    "    for i in range(3,7):\n",
    "        vote_count = int(line_data[i])\n",
    "        if(vote_count >= max_value):\n",
    "            max_index = i - 3\n",
    "            max_value = vote_count\n",
    "    line_data.append(max_index)\n",
    "    try:\n",
    "        script = get_script_from_id(line_data[0])\n",
    "    except:\n",
    "        #print('Error on loading script for id: ' + line_data[0])\n",
    "        continue\n",
    "    line_data.append(script)\n",
    "    df_data.append(line_data)\n",
    "\n",
    "# id | Aspect | None | Mild | Moderate | Severe | Total_votes | Aspect_rating | text\n",
    "df_all = pd.DataFrame(df_data, columns=['id', 'age_rating', 'Aspect', 'None', 'Mild', 'Moderate', 'Severe', 'Total_votes', 'Aspect_rating', 'text'])\n",
    "df_all.drop(columns=[\"age_rating\"], inplace=True)\n",
    "df_output = pd.merge(df_all, df_embs,how='inner', on='id')\n",
    "df_output.drop(columns=[\"text\"], inplace=True)\n",
    "df_output.rename(columns = {'sentences_emb':'text'}, inplace = True)\n",
    "df_output.reset_index(drop=True, inplace=True)\n",
    "df_output = df_output.astype({'Mild':'int', 'Moderate':'int', 'Severe':'int', 'None':'int', 'Total_votes':'int', 'Aspect_rating':'int'})\n",
    "print(df_output)\n",
    "print(df_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def map_data_frame_to_pickle(data_frame, file_name, path='./'):\n",
    "    file_name = f'{file_name}_emb.pkl'\n",
    "    with open(path + file_name, 'wb') as f:\n",
    "        data_frame.to_pickle(f, protocol=4)\n",
    "\n",
    "def split_df_into_test_and_train(aspect_name, df, path='./'):\n",
    "    df_train = df.sample(frac=0.85, random_state=0)\n",
    "    df_test = df.drop(df_train.index)\n",
    "    map_data_frame_to_pickle(df_train, f'{aspect_name}_train', '../data/pickle/')\n",
    "    map_data_frame_to_pickle(df_test, f'{aspect_name}_test', '../data/pickle/')\n",
    "    map_data_frame_to_pickle(df_test, f'{aspect_name}_dev', '../data/pickle/')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol 51\n",
      "frightening 51\n",
      "nudity 51\n",
      "profanity 51\n",
      "violence 51\n"
     ]
    }
   ],
   "source": [
    "# group the dataframe by 'aspect' and create a dictionary of dataframes\n",
    "df_dict = {aspect: aspect_df.drop('Aspect', axis=1) for aspect, aspect_df in df_output.groupby('Aspect')}\n",
    "\n",
    "# print the dictionary of dataframes\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    print(aspect, len(aspect_df))\n",
    "    split_df_into_test_and_train(aspect, aspect_df, '../data/pickle/emb_files/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  None  Mild  Moderate  Severe  Total_votes  Aspect_rating  \\\n",
      "3    tt0032138    76    10         1       6           93              0   \n",
      "18   tt0047396    18    87         5       0          110              1   \n",
      "48   tt0056869    10    53         6       0           69              1   \n",
      "98   tt0066026     5    11         6       0           22              1   \n",
      "198  tt0076759    79   157         5       5          246              1   \n",
      "223  tt0078841     3    15         0       1           19              1   \n",
      "238  tt0080339     7    68        38       9          122              1   \n",
      "248  tt0080745    20     6         1       0           27              0   \n",
      "\n",
      "                                                  text  \n",
      "3    [[tensor(0.1276), tensor(-0.1368), tensor(0.79...  \n",
      "18   [[tensor(-0.9443), tensor(-0.1430), tensor(0.1...  \n",
      "48   [[tensor(-0.3116), tensor(-0.1049), tensor(0.4...  \n",
      "98   [[tensor(-0.5252), tensor(0.4829), tensor(0.04...  \n",
      "198  [[tensor(0.0440), tensor(0.6131), tensor(0.337...  \n",
      "223  [[tensor(0.0040), tensor(0.1524), tensor(1.340...  \n",
      "238  [[tensor(-0.0452), tensor(0.7603), tensor(1.01...  \n",
      "248  [[tensor(0.1824), tensor(-0.1568), tensor(0.31...  \n"
     ]
    }
   ],
   "source": [
    " # Test the pickle generation\n",
    "\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    " # map_data_frame_to_pickle(df, 'train_emb')\n",
    "\n",
    "with open(\"../data/pickle/emb_files/alcohol_dev_emb.pkl\", \"rb\") as f:\n",
    "    object = pkl.load(f)\n",
    "    \n",
    "df = pd.DataFrame(object)\n",
    "print(df)\n",
    "#print(df['text_emb'][78].shape)\n",
    "#df.to_csv(r'train_emb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58a70258e14bd297a6daf9cfe92670f895d4f6fbf2bfd1d162369aa9303133c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
