{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read movie scripts from data directory and remove boilerplate\n",
    "def get_script_from_id(id):\n",
    "    script = open('../data/script/' + id + '.script', 'r').read()\n",
    "    # print(script)\n",
    "    script = script.replace(\"'\", \" \").replace('\"', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\b', ' ').replace('\\\\', ' ')\n",
    "    return script\n",
    "\n",
    "# Merge script data with labels crawled in data gathering\n",
    "def get_pd_dataframe():\n",
    "    inputFile = open('../data_gathering/baseline/output/imdb_id_with_age_rating_and_labels.txt')\n",
    "    df_data = []\n",
    "    for line in inputFile:\n",
    "        line_data = line.strip().split(',')\n",
    "        # print(line_data)\n",
    "        line_data.append(int(line_data[3]) + int(line_data[4]) + int(line_data[5]) + int(line_data[6]))\n",
    "        \n",
    "        max_index = 0\n",
    "        max_value = 0\n",
    "        for i in range(3,7):\n",
    "            vote_count = int(line_data[i])\n",
    "            if(vote_count >= max_value):\n",
    "                max_index = i - 3\n",
    "                max_value = vote_count\n",
    "        line_data.append(max_index)\n",
    "        try:\n",
    "            script = get_script_from_id(line_data[0])\n",
    "        except:\n",
    "            # print('Error on loading script for id: ' + line_data[0])\n",
    "            continue\n",
    "        line_data.append(script)\n",
    "        df_data.append(line_data)\n",
    "\n",
    "    # id | Aspect | None | Mild | Moderate | Severe | Total_votes | Aspect_rating | text\n",
    "    df = pd.DataFrame(df_data, columns=['imdb_id', 'age_rating', 'aspect', 'votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes', 'aspect_rating', 'text'])\n",
    "    df.drop(columns=[\"age_rating\"], inplace=True)\n",
    "    df = df.astype({'votes mild':'int', 'votes moderate':'int', 'votes severe':'int', 'votes none':'int', 'total_votes':'int', 'aspect_rating':'int'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download standard datasets for filtering movie scripts\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Text preprocessing class for preprocessing of movie scripts\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_processed = []\n",
    "        for text in X:\n",
    "            # Convert to lowercase and remove punctuation\n",
    "            text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            # Tokenize the text\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            # Remove stop words and lemmatize the remaining words\n",
    "            processed_tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words]\n",
    "            # Join the processed tokens back into a single string\n",
    "            processed_text = ' '.join(processed_tokens)\n",
    "            X_processed.append(processed_text)\n",
    "        return X_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = get_pd_dataframe()\n",
    "\n",
    "# Drop rows with less than 5 votes\n",
    "rows_to_drop = df.loc[df['total_votes'] < 5].index\n",
    "df = df.drop(rows_to_drop)\n",
    "\n",
    "# Group the dataframe by 'aspect' and create a dictionary of dataframes\n",
    "df_dict = {aspect: aspect_df.drop('aspect', axis=1) for aspect, aspect_df in df.groupby('aspect')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>votes none</th>\n",
       "      <th>votes mild</th>\n",
       "      <th>votes moderate</th>\n",
       "      <th>votes severe</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>aspect_rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0032138</td>\n",
       "      <td>23</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>FADE IN -- Title:  For nearly forty years this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>KATE AND ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tt0038650</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>IT S A WOND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tt0047396</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>REAR WI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tt0048545</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>REBEL ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdb_id  votes none  votes mild  votes moderate  votes severe  \\\n",
       "1   tt0032138          23          61               8             8   \n",
       "6   tt0035423           8           3               0             0   \n",
       "11  tt0038650          31          76               6             3   \n",
       "16  tt0047396          12          86               9             0   \n",
       "21  tt0048545           0           7              17             0   \n",
       "\n",
       "    total_votes  aspect_rating  \\\n",
       "1           100              1   \n",
       "6            11              0   \n",
       "11          116              1   \n",
       "16          107              1   \n",
       "21           24              2   \n",
       "\n",
       "                                                 text  \n",
       "1   FADE IN -- Title:  For nearly forty years this...  \n",
       "6                                        KATE AND ...  \n",
       "11                                     IT S A WOND...  \n",
       "16                                         REAR WI...  \n",
       "21                                          REBEL ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['violence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard method for text preprocessing and splitting the data into train and test sets\n",
    "def split_data(aspect_df, test_size=0.3):\n",
    "    text_transformer = Pipeline(steps=[('preprocess', TextPreprocessor())])\n",
    "    text = aspect_df['text']\n",
    "    preproccessed_text = text_transformer.fit_transform(text)\n",
    "    return train_test_split(preproccessed_text, aspect_df['aspect_rating'],test_size=test_size)\n",
    "\n",
    "# Standard method for text preprocessing and extracting features from labels\n",
    "def divide_label_features(aspect_df):\n",
    "    text_transformer = Pipeline(steps=[('preprocess', TextPreprocessor())])\n",
    "    text = aspect_df['text']\n",
    "    preproccessed_text = text_transformer.fit_transform(text)\n",
    "    return preproccessed_text, aspect_df['aspect_rating'].tolist()\n",
    "\n",
    "# Preprocessing for single prediction run without splitting the data\n",
    "def preprocess_light(preproccessed_text, X, Y):\n",
    "    Encoder = LabelEncoder()\n",
    "\n",
    "    Y = Encoder.fit_transform(Y)\n",
    "\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=2000)\n",
    "    Tfidf_vect.fit(preproccessed_text)\n",
    "\n",
    "    X_Tfidf = Tfidf_vect.transform(X)\n",
    "\n",
    "    return X_Tfidf\n",
    "\n",
    "# Using word2vec to extract features from text\n",
    "def preprocess(preproccessed_text, Train_X, Test_X, Train_Y, Test_Y):\n",
    "    Encoder = LabelEncoder()\n",
    "    Train_Y = Encoder.fit_transform(Train_Y)\n",
    "    Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=2000)\n",
    "    Tfidf_vect.fit(preproccessed_text)\n",
    "\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "    return Train_X_Tfidf, Test_X_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score of alcohol : 65.97222222222221 %\n",
      "Random Forest Accuracy Score of alcohol : 63.888888888888886 %\n",
      "SVM Accuracy Score of frightening : 36.36363636363637 %\n",
      "Random Forest Accuracy Score of frightening : 44.75524475524475 %\n",
      "SVM Accuracy Score of nudity : 43.05555555555556 %\n",
      "Random Forest Accuracy Score of nudity : 46.52777777777778 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m aspect_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mvotes none\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvotes mild\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvotes moderate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvotes severe\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtotal_votes\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Train_X, Test_X, Train_Y, Test_Y \u001b[39m=\u001b[39m split_data(aspect_df\u001b[39m=\u001b[39maspect_df)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m Train_X_Tfidf, Test_X_Tfidf \u001b[39m=\u001b[39m preprocess(aspect_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], Train_X, Test_X, Train_Y, Test_Y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m SVM \u001b[39m=\u001b[39m SVC(C\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, degree\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m SVM\u001b[39m.\u001b[39mfit(Train_X_Tfidf,Train_Y)\n",
      "\u001b[1;32m/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb Cell 8\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(preproccessed_text, Train_X, Test_X, Train_Y, Test_Y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m Test_Y \u001b[39m=\u001b[39m Encoder\u001b[39m.\u001b[39mfit_transform(Test_Y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m Tfidf_vect \u001b[39m=\u001b[39m TfidfVectorizer(max_features\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Tfidf_vect\u001b[39m.\u001b[39;49mfit(preproccessed_text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m Train_X_Tfidf \u001b[39m=\u001b[39m Tfidf_vect\u001b[39m.\u001b[39mtransform(Train_X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonremke/Documents/GIT_REPOS/UNI/dsta-movie-analytics/own_model/random_forest_improved_svm.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m Test_X_Tfidf \u001b[39m=\u001b[39m Tfidf_vect\u001b[39m.\u001b[39mtransform(Test_X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DSTA-Ex/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2053\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[1;32m   2052\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_for_unused_params()\n\u001b[0;32m-> 2053\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   2054\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[1;32m   2055\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DSTA-Ex/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1323\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1326\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m             )\n\u001b[1;32m   1328\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1333\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DSTA-Ex/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1205\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1203\u001b[0m feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[1;32m   1204\u001b[0m \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[0;32m-> 1205\u001b[0m     feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1207\u001b[0m     feature_counter[feature_idx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the model for each aspect (alcohol, frightening, nudity, violence, profanity)\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    aspect_df.drop(columns=['votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes'], inplace=True)\n",
    "\n",
    "    Train_X, Test_X, Train_Y, Test_Y = split_data(aspect_df=aspect_df)\n",
    "\n",
    "    Train_X_Tfidf, Test_X_Tfidf = preprocess(aspect_df['text'], Train_X, Test_X, Train_Y, Test_Y)\n",
    "\n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=42)\n",
    "    SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "    predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "    print(\"SVM Accuracy Score of\", aspect, \":\", accuracy_score(predictions_SVM, Test_Y)*100,\"%\")\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(max_depth=3, max_features=2000, random_state=42)\n",
    "    rf_classifier.fit(Train_X_Tfidf, Train_Y)\n",
    "    y_pred = rf_classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "    joblib.dump(rf_classifier, f'rf_classifier_{aspect}.joblib')\n",
    "    joblib.dump(SVM, f'svm_classifier_{aspect}.joblib')\n",
    "\n",
    "    accuracy = accuracy_score(Test_Y, y_pred)\n",
    "    print(\"Random Forest Accuracy Score of\", aspect, \":\", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score of alcohol : 65.97222222222221 %\n",
      "Random Forest Accuracy Score of alcohol : 65.97222222222221 %\n",
      "SVM Accuracy Score of frightening : 34.96503496503497 %\n",
      "Random Forest Accuracy Score of frightening : 46.15384615384615 %\n",
      "SVM Accuracy Score of nudity : 44.44444444444444 %\n",
      "Random Forest Accuracy Score of nudity : 50.69444444444444 %\n",
      "SVM Accuracy Score of profanity : 44.44444444444444 %\n",
      "Random Forest Accuracy Score of profanity : 54.166666666666664 %\n",
      "SVM Accuracy Score of violence : 34.02777777777778 %\n",
      "Random Forest Accuracy Score of violence : 56.94444444444444 %\n"
     ]
    }
   ],
   "source": [
    "# Model training and test run as monolith (SVM and Random Forest model from SKLearn)\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    aspect_df.drop(columns=['votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes'], inplace=True)\n",
    "    text_transformer = Pipeline(steps=[('preprocess', TextPreprocessor())])\n",
    "    text = aspect_df['text']\n",
    "    preproccessed_text = text_transformer.fit_transform(text)\n",
    "    Train_X, Test_X, Train_Y, Test_Y = train_test_split(preproccessed_text, aspect_df['aspect_rating'],test_size=0.3)\n",
    "\n",
    "    Encoder = LabelEncoder()\n",
    "    Train_Y = Encoder.fit_transform(Train_Y)\n",
    "    Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=2000)\n",
    "    Tfidf_vect.fit(preproccessed_text)\n",
    "\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=42)\n",
    "    SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "    predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "    print(\"SVM Accuracy Score of\", aspect, \":\", accuracy_score(predictions_SVM, Test_Y)*100,\"%\")\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(max_depth=3, max_features=2000, random_state=42)\n",
    "    rf_classifier.fit(Train_X_Tfidf, Train_Y)\n",
    "    y_pred = rf_classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "    joblib.dump(rf_classifier, f'rf_classifier_{aspect}.joblib')\n",
    "    joblib.dump(SVM, f'svm_classifier_{aspect}.joblib')\n",
    "\n",
    "    accuracy = accuracy_score(Test_Y, y_pred)\n",
    "    print(\"Random Forest Accuracy Score of\", aspect, \":\", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting model for aspect: alcohol\n",
      "Predicting model for aspect: frightening\n",
      "Predicting model for aspect: nudity\n",
      "Predicting model for aspect: profanity\n",
      "Predicting model for aspect: violence\n"
     ]
    }
   ],
   "source": [
    "# Predict on whole dataset for displaying in frontend\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    rf_classifier = joblib.load(f'./trained_models/rf_classifier_{aspect}.joblib')\n",
    "\n",
    "    X, Y = divide_label_features(aspect_df=aspect_df)\n",
    "    X_Tfidf = preprocess_light(aspect_df['text'], X, Y)\n",
    "\n",
    "    try:\n",
    "        print('Predicting model for aspect: ' + aspect)\n",
    "        y_pred = rf_classifier.predict(X_Tfidf)\n",
    "        df_dict[aspect][f'prediction_{aspect}'] = y_pred\n",
    "    except Exception as e:\n",
    "        print('Error on predicting model for aspect: ' + aspect + ' Error: ' + str(e))\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>prediction_alcohol</th>\n",
       "      <th>prediction_frightening</th>\n",
       "      <th>prediction_nudity</th>\n",
       "      <th>prediction_profanity</th>\n",
       "      <th>prediction_violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0032138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0038650</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0047396</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0048545</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id  prediction_alcohol  prediction_frightening  prediction_nudity  \\\n",
       "0  tt0032138                   1                       2                  3   \n",
       "1  tt0035423                   1                       2                  1   \n",
       "2  tt0038650                   1                       2                  1   \n",
       "3  tt0047396                   1                       2                  1   \n",
       "4  tt0048545                   1                       2                  1   \n",
       "\n",
       "   prediction_profanity  prediction_violence  \n",
       "0                     1                    1  \n",
       "1                     1                    1  \n",
       "2                     2                    1  \n",
       "3                     1                    1  \n",
       "4                     1                    2  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting raw predictions as preparation for elastic search\n",
    "from functools import reduce\n",
    "\n",
    "df_list = list(df_dict.values())\n",
    "\n",
    "# Define the common columns on which the data frames will be merged\n",
    "# for df in df_list:\n",
    "#     # df.drop(columns=[\"text\"], inplace=True)\n",
    "#     df.drop(columns=[\"aspect_rating\"], inplace=True)\n",
    "# # Apply the merge function to all data frames in the list\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, how=\"inner\", on=\"imdb_id\"), df_list)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../data/results_models/rf_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSTA-Ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
