{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_from_id(id):\n",
    "    script = open('../data/script/' + id + '.script', 'r').read()\n",
    "    # print(script)\n",
    "    script = script.replace(\"'\", \" \").replace('\"', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\b', ' ').replace('\\\\', ' ')\n",
    "    return script\n",
    "\n",
    "def get_pd_dataframe():\n",
    "    inputFile = open('../data_gathering/baseline/output/imdb_id_with_age_rating_and_labels.txt')\n",
    "    df_data = []\n",
    "    for line in inputFile:\n",
    "        line_data = line.strip().split(',')\n",
    "        # print(line_data)\n",
    "        line_data.append(int(line_data[3]) + int(line_data[4]) + int(line_data[5]) + int(line_data[6]))\n",
    "        \n",
    "        max_index = 0\n",
    "        max_value = 0\n",
    "        for i in range(3,7):\n",
    "            vote_count = int(line_data[i])\n",
    "            if(vote_count >= max_value):\n",
    "                max_index = i - 3\n",
    "                max_value = vote_count\n",
    "        line_data.append(max_index)\n",
    "        try:\n",
    "            script = get_script_from_id(line_data[0])\n",
    "        except:\n",
    "            # print('Error on loading script for id: ' + line_data[0])\n",
    "            continue\n",
    "        line_data.append(script)\n",
    "        df_data.append(line_data)\n",
    "\n",
    "    # id | Aspect | None | Mild | Moderate | Severe | Total_votes | Aspect_rating | text\n",
    "    df = pd.DataFrame(df_data, columns=['imdb_id', 'age_rating', 'aspect', 'votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes', 'aspect_rating', 'text'])\n",
    "    df.drop(columns=[\"age_rating\"], inplace=True)\n",
    "    df = df.astype({'votes mild':'int', 'votes moderate':'int', 'votes severe':'int', 'votes none':'int', 'total_votes':'int', 'aspect_rating':'int'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# Define a custom transformer to preprocess the text column\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_processed = []\n",
    "        for text in X:\n",
    "            # Convert to lowercase and remove punctuation\n",
    "            text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            # Tokenize the text\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            # Remove stop words and lemmatize the remaining words\n",
    "            processed_tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words]\n",
    "            # Join the processed tokens back into a single string\n",
    "            processed_text = ' '.join(processed_tokens)\n",
    "            X_processed.append(processed_text)\n",
    "        return X_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMMovieClassifier():\n",
    "\n",
    "    def __init__(self, df, model_name, num_features):\n",
    "\n",
    "        self.df = df\n",
    "        # Define the column transformer\n",
    "        self.num_features = num_features\n",
    "        self.num_transformer = Pipeline(steps=[\n",
    "            ('normalize', FunctionTransformer(lambda x: x[num_features].div(x['total_votes'], axis=0), validate=False)),\n",
    "            ('scale', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        self.text_transformer = Pipeline(steps=[\n",
    "            ('preprocess', TextPreprocessor()),\n",
    "            ('vectorize', TfidfVectorizer())\n",
    "        ])\n",
    "\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            # ('num', self.num_transformer, num_features),\n",
    "            ('text', self.text_transformer, 'text')\n",
    "        ])\n",
    "\n",
    "        # Define the pipeline\n",
    "        self.pipe = Pipeline(steps=[\n",
    "            ('preprocess', self.preprocessor),\n",
    "            ('clf', SVC())\n",
    "        ])\n",
    "\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def split_data(self):\n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.df.drop('aspect_rating', axis=1), self.df['aspect_rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "    def train(self):\n",
    "        # Train the pipeline\n",
    "        self.pipe.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def test(self, X_test = None, y_test = None):\n",
    "        # Test the pipeline\n",
    "        if X_test is None or y_test is None:\n",
    "            X_test = self.X_test\n",
    "            y_test = self.y_test\n",
    "\n",
    "        y_pred = self.pipe.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        # Save the pipeline\n",
    "        joblib.dump(self.pipe, model_name)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        # Load the pipeline\n",
    "        self.pipe = joblib.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol 477\n",
      "frightening 475\n",
      "nudity 478\n",
      "profanity 477\n",
      "violence 477\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = get_pd_dataframe()\n",
    "\n",
    "# Drop rows with less than 5 votes\n",
    "rows_to_drop = df.loc[df['total_votes'] < 5].index\n",
    "df = df.drop(rows_to_drop)\n",
    "\n",
    "# group the dataframe by 'aspect' and create a dictionary of dataframes\n",
    "df_dict = {aspect: aspect_df.drop('aspect', axis=1) for aspect, aspect_df in df.groupby('aspect')}\n",
    "\n",
    "aspect_classifier_dict = {}\n",
    "\n",
    "# print the dictionary of dataframes\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    print(aspect, len(aspect_df))\n",
    "    # Limit the number of rows to 50 for testing\n",
    "    aspect_classifier_dict[aspect] = SVMMovieClassifier(aspect_df, 'movie_svm_' + aspect, ['votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for aspect: alcohol\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "    try:\n",
    "        print('Training model for aspect: ' + aspect)\n",
    "        movie_classifier.split_data()\n",
    "        movie_classifier.train()\n",
    "    except Exception as e:\n",
    "        print('Error on training model for aspect: ' + aspect)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model for aspect: alcohol\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00        55\n",
      "           2       1.00      1.00      1.00        23\n",
      "           3       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        96\n",
      "   macro avg       1.00      1.00      1.00        96\n",
      "weighted avg       1.00      1.00      1.00        96\n",
      "\n",
      "Testing model for aspect: frightening\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.93      1.00      0.96        26\n",
      "           2       0.97      1.00      0.98        32\n",
      "           3       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.97        95\n",
      "   macro avg       0.97      0.95      0.96        95\n",
      "weighted avg       0.97      0.97      0.97        95\n",
      "\n",
      "Testing model for aspect: nudity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        28\n",
      "           1       0.95      1.00      0.97        39\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.98        96\n",
      "   macro avg       0.99      0.98      0.98        96\n",
      "weighted avg       0.98      0.98      0.98        96\n",
      "\n",
      "Testing model for aspect: profanity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        33\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        96\n",
      "   macro avg       1.00      1.00      1.00        96\n",
      "weighted avg       1.00      1.00      1.00        96\n",
      "\n",
      "Testing model for aspect: violence\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        37\n",
      "           3       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        96\n",
      "   macro avg       1.00      1.00      1.00        96\n",
      "weighted avg       1.00      1.00      1.00        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "    try:\n",
    "        print('Testing model for aspect: ' + aspect)\n",
    "        movie_classifier.test()\n",
    "    except Exception as e:\n",
    "        print('Error on testing model for aspect: ' + aspect + ' Error: ' + str(e))\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSTA-Ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
