{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_from_id(id):\n",
    "    script = open('../data/script/' + id + '.script', 'r').read()\n",
    "    # print(script)\n",
    "    script = script.replace(\"'\", \" \").replace('\"', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\b', ' ').replace('\\\\', ' ')\n",
    "    return script\n",
    "\n",
    "def get_pd_dataframe():\n",
    "    inputFile = open('../data_gathering/baseline/output/imdb_id_with_age_rating_and_labels.txt')\n",
    "    df_data = []\n",
    "    for line in inputFile:\n",
    "        line_data = line.strip().split(',')\n",
    "        # print(line_data)\n",
    "        line_data.append(int(line_data[3]) + int(line_data[4]) + int(line_data[5]) + int(line_data[6]))\n",
    "        \n",
    "        max_index = 0\n",
    "        max_value = 0\n",
    "        for i in range(3,7):\n",
    "            vote_count = int(line_data[i])\n",
    "            if(vote_count >= max_value):\n",
    "                max_index = i - 3\n",
    "                max_value = vote_count\n",
    "        line_data.append(max_index)\n",
    "        try:\n",
    "            script = get_script_from_id(line_data[0])\n",
    "        except:\n",
    "            # print('Error on loading script for id: ' + line_data[0])\n",
    "            continue\n",
    "        line_data.append(script)\n",
    "        df_data.append(line_data)\n",
    "\n",
    "    # id | Aspect | None | Mild | Moderate | Severe | Total_votes | Aspect_rating | text\n",
    "    df = pd.DataFrame(df_data, columns=['imdb_id', 'age_rating', 'aspect', 'votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes', 'aspect_rating', 'text'])\n",
    "    df.drop(columns=[\"age_rating\"], inplace=True)\n",
    "    df = df.astype({'votes mild':'int', 'votes moderate':'int', 'votes severe':'int', 'votes none':'int', 'total_votes':'int', 'aspect_rating':'int'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leonremke/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# Define a custom transformer to preprocess the text column\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_processed = []\n",
    "        for text in X:\n",
    "            # Convert to lowercase and remove punctuation\n",
    "            text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            # Tokenize the text\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            # Remove stop words and lemmatize the remaining words\n",
    "            processed_tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words]\n",
    "            # Join the processed tokens back into a single string\n",
    "            processed_text = ' '.join(processed_tokens)\n",
    "            X_processed.append(processed_text)\n",
    "        return X_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMMovieClassifier():\n",
    "\n",
    "    def __init__(self, df, model_name, num_features):\n",
    "\n",
    "        self.df = df\n",
    "        # Define the column transformer\n",
    "        self.num_features = num_features\n",
    "        self.num_transformer = Pipeline(steps=[\n",
    "            ('normalize', FunctionTransformer(lambda x: x[num_features].div(x['total_votes'], axis=0), validate=False)),\n",
    "            ('scale', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        self.text_transformer = Pipeline(steps=[\n",
    "            ('preprocess', TextPreprocessor()),\n",
    "            ('vectorize', TfidfVectorizer())\n",
    "        ])\n",
    "\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            # ('num', self.num_transformer, num_features),\n",
    "            ('text', self.text_transformer, 'text')\n",
    "        ])\n",
    "\n",
    "        # Define the pipeline\n",
    "        self.pipe = Pipeline(steps=[\n",
    "            ('preprocess', self.preprocessor),\n",
    "            ('clf', SVC())\n",
    "        ])\n",
    "\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def split_data(self):\n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.df.drop('aspect_rating', axis=1), self.df['aspect_rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "    def train(self):\n",
    "        # Train the pipeline\n",
    "        self.pipe.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def test(self, X_test = None, y_test = None):\n",
    "        # Test the pipeline\n",
    "        if X_test is None or y_test is None:\n",
    "            X_test = self.X_test\n",
    "            y_test = self.y_test\n",
    "\n",
    "        y_pred = self.pipe.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    def predict_and_save(self, X, save_path = \"./\", save_name = \"prediction.csv\"):\n",
    "        # Predict the labels\n",
    "        y_pred = self.pipe.predict(X)\n",
    "        X['prediction'] = y_pred\n",
    "        X.drop(columns=['text'], inplace=True)\n",
    "        X.to_csv(save_path + save_name, index=False)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the labels\n",
    "        y_pred = self.pipe.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        # Save the pipeline\n",
    "        joblib.dump(self.pipe, model_name)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        # Load the pipeline\n",
    "        self.pipe = joblib.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = get_pd_dataframe()\n",
    "\n",
    "# Drop rows with less than 5 votes\n",
    "rows_to_drop = df.loc[df['total_votes'] < 5].index\n",
    "df = df.drop(rows_to_drop)\n",
    "\n",
    "# group the dataframe by 'aspect' and create a dictionary of dataframes\n",
    "df_dict = {aspect: aspect_df.drop('aspect', axis=1) for aspect, aspect_df in df.groupby('aspect')}\n",
    "\n",
    "aspect_classifier_dict = {}\n",
    "\n",
    "# print the dictionary of dataframes\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    print(aspect, len(aspect_df))\n",
    "    # Limit the number of rows to 50 for testing\n",
    "    aspect_classifier_dict[aspect] = SVMMovieClassifier(aspect_df, 'movie_svm_' + aspect, ['votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for aspect: alcohol\n",
      "Training model for aspect: frightening\n",
      "Training model for aspect: nudity\n",
      "Training model for aspect: profanity\n",
      "Training model for aspect: violence\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "    try:\n",
    "        print('Training model for aspect: ' + aspect)\n",
    "        movie_classifier.split_data()\n",
    "        movie_classifier.train()\n",
    "    except Exception as e:\n",
    "        print('Error on training model for aspect: ' + aspect)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test the model\n",
    "# for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "#     try:\n",
    "#         print('Testing model for aspect: ' + aspect)\n",
    "#         movie_classifier.test()\n",
    "#     except Exception as e:\n",
    "#         print('Error on testing model for aspect: ' + aspect + ' Error: ' + str(e))\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting model for aspect: alcohol\n",
      "Predicting model for aspect: frightening\n",
      "Predicting model for aspect: nudity\n",
      "Predicting model for aspect: profanity\n",
      "Predicting model for aspect: violence\n"
     ]
    }
   ],
   "source": [
    "for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "    final_df = df_dict[\"frightening\"].drop(columns=[\"text\", \"aspect_rating\"])\n",
    "    try:\n",
    "        print('Predicting model for aspect: ' + aspect)\n",
    "        y_pred = movie_classifier.predict(df_dict[aspect])\n",
    "        df_dict[aspect][f'prediction_{aspect}'] = y_pred\n",
    "    except Exception as e:\n",
    "        print('Error on predicting model for aspect: ' + aspect + ' Error: ' + str(e))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>prediction_alcohol</th>\n",
       "      <th>prediction_frightening</th>\n",
       "      <th>prediction_nudity</th>\n",
       "      <th>prediction_profanity</th>\n",
       "      <th>prediction_violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0032138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0038650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0047396</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0048545</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id  prediction_alcohol  prediction_frightening  prediction_nudity  \\\n",
       "0  tt0032138                   1                       2                  1   \n",
       "1  tt0035423                   1                       1                  0   \n",
       "2  tt0038650                   1                       1                  0   \n",
       "3  tt0047396                   1                       1                  1   \n",
       "4  tt0048545                   1                       2                  0   \n",
       "\n",
       "   prediction_profanity  prediction_violence  \n",
       "0                     1                    2  \n",
       "1                     1                    0  \n",
       "2                     1                    1  \n",
       "3                     0                    1  \n",
       "4                     0                    2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "df_list = list(df_dict.values())\n",
    "\n",
    "# Define the common columns on which the data frames will be merged\n",
    "\n",
    "for df in df_list:\n",
    "    df.drop(columns=[\"text\", \"aspect_rating\", \"votes none\", \"votes mild\", \"votes moderate\", \"votes severe\", \"total_votes\"], inplace=True)\n",
    "# Apply the merge function to all data frames in the list\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, how=\"inner\", on=\"imdb_id\"), df_list)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"../data/results_svm/svm_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSTA-Ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
