{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_from_id(id):\n",
    "    script = open('../data/script/' + id + '.script', 'r').read()\n",
    "    # print(script)\n",
    "    script = script.replace(\"'\", \" \").replace('\"', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\b', ' ').replace('\\\\', ' ')\n",
    "    return script\n",
    "\n",
    "def get_pd_dataframe():\n",
    "    inputFile = open('../data_gathering/baseline/output/imdb_id_with_age_rating_and_labels.txt')\n",
    "    df_data = []\n",
    "    for line in inputFile:\n",
    "        line_data = line.strip().split(',')\n",
    "        # print(line_data)\n",
    "        line_data.append(int(line_data[3]) + int(line_data[4]) + int(line_data[5]) + int(line_data[6]))\n",
    "        \n",
    "        max_index = 0\n",
    "        max_value = 0\n",
    "        for i in range(3,7):\n",
    "            vote_count = int(line_data[i])\n",
    "            if(vote_count >= max_value):\n",
    "                max_index = i - 3\n",
    "                max_value = vote_count\n",
    "        line_data.append(max_index)\n",
    "        try:\n",
    "            script = get_script_from_id(line_data[0])\n",
    "        except:\n",
    "            # print('Error on loading script for id: ' + line_data[0])\n",
    "            continue\n",
    "        line_data.append(script)\n",
    "        df_data.append(line_data)\n",
    "\n",
    "    # id | Aspect | None | Mild | Moderate | Severe | Total_votes | Aspect_rating | text\n",
    "    df = pd.DataFrame(df_data, columns=['imdb_id', 'age_rating', 'aspect', 'votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes', 'aspect_rating', 'text'])\n",
    "    df.drop(columns=[\"age_rating\"], inplace=True)\n",
    "    df = df.astype({'votes mild':'int', 'votes moderate':'int', 'votes severe':'int', 'votes none':'int', 'total_votes':'int', 'aspect_rating':'int'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/I518302/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/I518302/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/I518302/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# Define a custom transformer to preprocess the text column\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_processed = []\n",
    "        for text in X:\n",
    "            # Convert to lowercase and remove punctuation\n",
    "            text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            # Tokenize the text\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            # Remove stop words and lemmatize the remaining words\n",
    "            processed_tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words]\n",
    "            # Join the processed tokens back into a single string\n",
    "            processed_text = ' '.join(processed_tokens)\n",
    "            X_processed.append(processed_text)\n",
    "        return X_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMMovieClassifier():\n",
    "\n",
    "    def __init__(self, df, model_name, num_features):\n",
    "\n",
    "        self.df = df\n",
    "        # Define the column transformer\n",
    "        self.num_features = 1 #num_features\n",
    "        self.num_transformer = Pipeline(steps=[\n",
    "            ('normalize', FunctionTransformer(lambda x: x[num_features].div(x['total_votes'], axis=0), validate=False)),\n",
    "            ('scale', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        self.text_transformer = Pipeline(steps=[\n",
    "            ('preprocess', TextPreprocessor()),\n",
    "            ('vectorize', TfidfVectorizer())\n",
    "        ])\n",
    "\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', self.num_transformer, num_features),\n",
    "            ('text', self.text_transformer, 'text')\n",
    "        ])\n",
    "\n",
    "        # Define the pipeline\n",
    "        self.pipe = Pipeline(steps=[\n",
    "            ('preprocess', self.preprocessor),\n",
    "            ('clf', SVC())\n",
    "        ])\n",
    "\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def split_data(self):\n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.df['text'], self.df['aspect_rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "    def train(self):\n",
    "        # Train the pipeline\n",
    "        self.pipe.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def test(self, X_test = None, y_test = None):\n",
    "        # Test the pipeline\n",
    "        if X_test is None or y_test is None:\n",
    "            X_test = self.X_test\n",
    "            y_test = self.y_test\n",
    "\n",
    "        y_pred = self.pipe.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        # Save the pipeline\n",
    "        joblib.dump(self.pipe, model_name)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        # Load the pipeline\n",
    "        self.pipe = joblib.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol 477\n",
      "frightening 475\n",
      "nudity 478\n",
      "profanity 477\n",
      "violence 477\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = get_pd_dataframe()\n",
    "\n",
    "# Drop rows with less than 5 votes\n",
    "rows_to_drop = df.loc[df['total_votes'] < 5].index\n",
    "df = df.drop(rows_to_drop)\n",
    "\n",
    "# group the dataframe by 'aspect' and create a dictionary of dataframes\n",
    "df_dict = {aspect: aspect_df.drop('aspect', axis=1) for aspect, aspect_df in df.groupby('aspect')}\n",
    "\n",
    "aspect_classifier_dict = {}\n",
    "\n",
    "# print the dictionary of dataframes\n",
    "for aspect, aspect_df in df_dict.items():\n",
    "    print(aspect, len(aspect_df))\n",
    "    # Limit the number of rows to 50 for testing\n",
    "    aspect_df = aspect_df[:50]\n",
    "    aspect_classifier_dict[aspect] = SVMMovieClassifier(aspect_df, 'movie_svm_' + aspect, ['votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for aspect: alcohol\n",
      "Error on training model for aspect: alcohol\n",
      "tuple index out of range\n",
      "Training model for aspect: frightening\n",
      "Error on training model for aspect: frightening\n",
      "tuple index out of range\n",
      "Training model for aspect: nudity\n",
      "Error on training model for aspect: nudity\n",
      "tuple index out of range\n",
      "Training model for aspect: profanity\n",
      "Error on training model for aspect: profanity\n",
      "tuple index out of range\n",
      "Training model for aspect: violence\n",
      "Error on training model for aspect: violence\n",
      "tuple index out of range\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "    try:\n",
    "        print('Training model for aspect: ' + aspect)\n",
    "        movie_classifier.split_data()\n",
    "        movie_classifier.train()\n",
    "    except Exception as e:\n",
    "        print('Error on training model for aspect: ' + aspect)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model for aspect: alcohol\n",
      "Error on testing model for aspect: alcohol Error: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "Testing model for aspect: frightening\n",
      "Error on testing model for aspect: frightening Error: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "Testing model for aspect: nudity\n",
      "Error on testing model for aspect: nudity Error: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "Testing model for aspect: profanity\n",
      "Error on testing model for aspect: profanity Error: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "Testing model for aspect: violence\n",
      "Error on testing model for aspect: violence Error: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "for aspect, movie_classifier in aspect_classifier_dict.items():\n",
    "    try:\n",
    "        print('Testing model for aspect: ' + aspect)\n",
    "        movie_classifier.test()\n",
    "    except Exception as e:\n",
    "        print('Error on testing model for aspect: ' + aspect + ' Error: ' + str(e))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>aspect_rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0032138</td>\n",
       "      <td>1</td>\n",
       "      <td>FADE IN -- Title:  For nearly forty years this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>0</td>\n",
       "      <td>KATE AND ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tt0038650</td>\n",
       "      <td>1</td>\n",
       "      <td>IT S A WOND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tt0047396</td>\n",
       "      <td>1</td>\n",
       "      <td>REAR WI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tt0048545</td>\n",
       "      <td>2</td>\n",
       "      <td>REBEL ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdb_id  aspect_rating  \\\n",
       "1   tt0032138              1   \n",
       "6   tt0035423              0   \n",
       "11  tt0038650              1   \n",
       "16  tt0047396              1   \n",
       "21  tt0048545              2   \n",
       "\n",
       "                                                 text  \n",
       "1   FADE IN -- Title:  For nearly forty years this...  \n",
       "6                                        KATE AND ...  \n",
       "11                                     IT S A WOND...  \n",
       "16                                         REAR WI...  \n",
       "21                                          REBEL ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['violence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score of alcohol : 63.888888888888886 %\n",
      "Random Forest Accuracy Score of alcohol : 68.05555555555556 %\n",
      "SVM Accuracy Score of frightening : 38.46153846153847 %\n",
      "Random Forest Accuracy Score of frightening : 46.85314685314685 %\n",
      "SVM Accuracy Score of nudity : 43.75 %\n",
      "Random Forest Accuracy Score of nudity : 46.52777777777778 %\n",
      "SVM Accuracy Score of profanity : 37.5 %\n",
      "Random Forest Accuracy Score of profanity : 65.27777777777779 %\n",
      "SVM Accuracy Score of violence : 35.41666666666667 %\n",
      "Random Forest Accuracy Score of violence : 51.388888888888886 %\n"
     ]
    }
   ],
   "source": [
    "for aspect, aspect_df in df_dict.items():\n",
    "    #aspect_df.drop(columns=['votes none', 'votes mild', 'votes moderate', 'votes severe', 'total_votes'], inplace=True)\n",
    "    text_transformer = Pipeline(steps=[('preprocess', TextPreprocessor())])\n",
    "    text = aspect_df['text']\n",
    "    preproccessed_text = text_transformer.fit_transform(text)\n",
    "    Train_X, Test_X, Train_Y, Test_Y = train_test_split(preproccessed_text, aspect_df['aspect_rating'],test_size=0.3)\n",
    "\n",
    "    Encoder = LabelEncoder()\n",
    "    Train_Y = Encoder.fit_transform(Train_Y)\n",
    "    Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=2000)\n",
    "    Tfidf_vect.fit(preproccessed_text)\n",
    "\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "    SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=42)\n",
    "    SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "    predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "    print(\"SVM Accuracy Score of\", aspect, \":\", accuracy_score(predictions_SVM, Test_Y)*100,\"%\")\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(max_depth=3, max_features=2000, random_state=42)\n",
    "    rf_classifier.fit(Train_X_Tfidf, Train_Y)\n",
    "    y_pred = rf_classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "    accuracy = accuracy_score(Test_Y, y_pred)\n",
    "    print(\"Random Forest Accuracy Score of\", aspect, \":\", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSTA-Ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
